{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./DataGen2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standard_Param():\n",
    "    def __init__(self, NumberOfClusters = 40):\n",
    "        # Region of interest :\n",
    "        self.x_lim = [0, 4] # micrometer\n",
    "        self.y_lim = [0, 4]\n",
    "\n",
    "        # Clusters :\n",
    "        self.NumberOfClusters = NumberOfClusters\n",
    "        self.LocPerCluster    = [24] * self.NumberOfClusters\n",
    "        self.r                = [30] * self.NumberOfClusters # nm\n",
    "        self.cluster_shape    = 'uniform'\n",
    "\n",
    "        # Noise :\n",
    "        self.NoisePercentage  = 0.5 # between 0 and 0.8\n",
    "        self.UniformNoise     = True \n",
    "        \n",
    "        # SMLM points : \n",
    "        self.mean_uncertainty      = 20\n",
    "        self.dev_uncertainty       = 3\n",
    "        self.N_photons             = 15000\n",
    "        \n",
    "        # Cluster elongation \n",
    "        self.elongation     = 1\n",
    "        \n",
    "        \n",
    "        # Scales : \n",
    "        self.NumberOfScales   = 1\n",
    "        \n",
    "        # RandomSeed \n",
    "        self.RandomSeed = 0 # 0 stands for no random seed\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Call_DataGenerator(p):\n",
    "    datagen = DataGenerator(x_lim = p.x_lim,\n",
    "                        y_lim = p.y_lim,\n",
    "                        NumberOfClusters = p.NumberOfClusters,\n",
    "                        LocPerCluster = p.LocPerCluster,\n",
    "                        r = p.r,\n",
    "                        NoisePercentage = p.NoisePercentage,\n",
    "                        NumberOfScales = p.NumberOfScales,\n",
    "                        cluster_shape = p.cluster_shape,\n",
    "                        UniformNoise = p.UniformNoise, \n",
    "                        mean_delta = p.mean_uncertainty, \n",
    "                        dev_delta = p.dev_uncertainty,\n",
    "                        N_photons = p.N_photons,\n",
    "                        elongation = p.elongation)\n",
    "    return datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_Standard(general_path, NumberOfSimulations = 30):\n",
    "    print('in generate standard')\n",
    "    \n",
    "    # Load the standard parameters:\n",
    "    p = Standard_Param()\n",
    "    \n",
    "    # Name of the last folder and of the first part of the csv file \n",
    "    name = 'simulated_SMLM_1'\n",
    "    folder = 'standard'\n",
    "    \n",
    "    for i in range(NumberOfSimulations):\n",
    "        if (i == 0): print(p.__dict__)\n",
    "        datagen = Call_DataGenerator(p)\n",
    "        datagen.save_to_csv(general_path + folder , name + '_' + str(i)) # saving a csv file at each iteration\n",
    "    \n",
    "\n",
    "def Generate_LowDensity(general_path, NumberOfSimulations = 30):\n",
    "    print('in generate low density')\n",
    "    # Load the standard parameters:\n",
    "    p = Standard_Param()\n",
    "\n",
    "    # Name of the last folder and of the first part of the csv file \n",
    "    name = 'simulated_SMLM_2'\n",
    "    folder = 'low_density'\n",
    "    \n",
    "    # Changing some of the paramters: (LocPerCluster in this case)\n",
    "    p.LocPerCluster    = [12] * p.NumberOfClusters\n",
    "    \n",
    "    for i in range(NumberOfSimulations):\n",
    "        if (i == 0): print(p.__dict__)\n",
    "        datagen = Call_DataGenerator(p)\n",
    "        datagen.save_to_csv(general_path + folder , name + '_' + str(i)) # saving a csv file at each iteration\n",
    "    \n",
    "def Generate_HighNoise(general_path, NumberOfSimulations = 30):\n",
    "    print('in generate high noise')\n",
    "    # Load the standard parameters:\n",
    "    p = Standard_Param()\n",
    "\n",
    "    # Name of the last folder and of the first part of the csv file \n",
    "    name = 'simulated_SMLM_3'\n",
    "    folder = 'high_noise'\n",
    "    \n",
    "    # Changing some of the paramters: (LocPerCluster in this case)\n",
    "    p.NoisePercentage  = 0.75\n",
    "    \n",
    "    for i in range(NumberOfSimulations):\n",
    "        if (i == 0): print(p.__dict__)\n",
    "        datagen = Call_DataGenerator(p)\n",
    "        datagen.save_to_csv(general_path + folder , name + '_' + str(i)) # saving a csv file at each iteration\n",
    "\n",
    "def Generate_DifferentDensities(general_path, NumberOfSimulations = 30):\n",
    "    print('in generate different densities')\n",
    "    # Load the standard parameters:\n",
    "    p = Standard_Param()\n",
    "\n",
    "    # Name of the last folder and of the first part of the csv file \n",
    "    name = 'simulated_SMLM_4'\n",
    "    folder = 'different_densities'\n",
    "    \n",
    "    # Changing some of the paramters: (LocPerCluster in this case)\n",
    "    mean_loc         = 25\n",
    "    dev              = 15\n",
    "\n",
    "    for i in range(NumberOfSimulations):\n",
    "        p.LocPerCluster   = np.random.uniform(low = mean_loc - dev, high = mean_loc + dev,\n",
    "                                        size = (p.NumberOfClusters, 1))\n",
    "\n",
    "        p.LocPerCluster  = [int(n) for n in p.LocPerCluster]\n",
    "        if (i == 0): print(p.__dict__)\n",
    "        datagen = Call_DataGenerator(p)\n",
    "        datagen.save_to_csv(general_path + folder , name + '_' + str(i)) # saving a csv file at each iteration\n",
    "        \n",
    "        \n",
    "def Generate_DifferentSizes(general_path, NumberOfSimulations = 30):\n",
    "    print('in generate different sizes')\n",
    "    # Load the standard parameters:\n",
    "    p = Standard_Param()\n",
    "\n",
    "    # Name of the last folder and of the first part of the csv file \n",
    "    name = 'simulated_SMLM_5'\n",
    "    folder = 'different_sizes'\n",
    "    \n",
    "    # Changing some of the paramters: (The radii and the number of localizations per cluster)\n",
    "    mean_r           = 40\n",
    "    dev_r            = 20\n",
    "    density          = p.LocPerCluster[0]/(math.pi * 30**2)\n",
    "\n",
    "    for i in range(NumberOfSimulations):\n",
    "        p.r   = np.random.uniform(low = mean_r - dev_r, high = mean_r + dev_r,\n",
    "                                        size = p.NumberOfClusters)\n",
    "        \n",
    "        p.LocPerCluster = [density * math.pi * radius**2 for radius in p.r]\n",
    "        \n",
    "        if (i == 0): print(p.__dict__)\n",
    "        datagen = Call_DataGenerator(p)\n",
    "        datagen.save_to_csv(general_path + folder , name + '_' + str(i)) # saving a csv file at each iteration\n",
    "        \n",
    "        \n",
    "        \n",
    "def Generate_NonUniformNoise(general_path, NumberOfSimulations = 30):\n",
    "    print('in generate different sizes')\n",
    "    # Load the standard parameters:\n",
    "    p = Standard_Param()\n",
    "\n",
    "    # Name of the last folder and of the first part of the csv file \n",
    "    name = 'simulated_SMLM_6'\n",
    "    folder = 'non_uniform_noise'\n",
    "\n",
    "    \n",
    "    # Changing some of the paramters: (In this case: non-uniform noise)\n",
    "    p.UniformNoise = False\n",
    "    \n",
    "    for i in range(NumberOfSimulations):\n",
    "        if (i == 0): print(p.__dict__)\n",
    "        datagen = Call_DataGenerator(p)\n",
    "        datagen.save_to_csv(general_path + folder , name + '_' + str(i)) # saving a csv file at each iteration\n",
    "\n",
    "        \n",
    "def Generate_Elongated(general_path, NumberOfSimulations = 30):\n",
    "    print('in generate elongated')\n",
    "    \n",
    "    # Load the standard parameters:\n",
    "    p = Standard_Param()\n",
    "    \n",
    "    # Name of the last folder and of the first part of the csv file \n",
    "    name = 'simulated_SMLM_7'\n",
    "    folder = 'elongated'\n",
    "\n",
    "    for i in range(NumberOfSimulations):\n",
    "        if (i == 0): print(p.__dict__)\n",
    "        datagen = Call_DataGenerator(p)\n",
    "        datagen.save_to_csv(general_path + folder , name + '_' + str(i)) # saving a csv file at each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_path = '/Users/Eliana/Documents/PDM/Codes/My_codes/Deviations_from_standard/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in generate different densities\n",
      "{'x_lim': [0, 4], 'y_lim': [0, 4], 'NumberOfClusters': 40, 'LocPerCluster': [37, 38, 23, 30, 20, 15, 23, 35, 20, 20, 26, 21, 39, 10, 36, 12, 17, 10, 16, 34, 14, 35, 34, 35, 12, 22, 17, 16, 38, 21, 36, 28, 29, 12, 30, 34, 21, 29, 24, 29], 'r': [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30], 'cluster_shape': 'uniform', 'NoisePercentage': 0.5, 'UniformNoise': True, 'mean_uncertainty': 20, 'dev_uncertainty': 3, 'N_photons': 150, 'elongation': 1, 'NumberOfScales': 1}\n",
      "in generate different sizes\n",
      "{'x_lim': [0, 4], 'y_lim': [0, 4], 'NumberOfClusters': 40, 'LocPerCluster': [24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24], 'r': array([36.83819343, 17.41882589, 15.54235492, 36.93740906, 27.9596443 ,\n",
      "       24.9573684 , 16.60202522, 44.50320453, 40.03371504, 27.2042764 ,\n",
      "       31.82207103, 25.4120239 , 23.0829001 , 42.66558334, 39.04816007,\n",
      "       22.18948954, 16.55154623, 32.53889177, 24.53954044, 21.70701319,\n",
      "       25.82285522, 44.86068085, 17.73283773, 40.70318106, 35.89107451,\n",
      "       39.4982699 , 24.81263754, 33.83471369, 17.64373062, 21.09370314,\n",
      "       42.13111336, 39.64842775, 40.91205772, 22.22806306, 37.01342161,\n",
      "       17.13160894, 28.73640749, 30.11782157, 31.26503419, 26.14599966]), 'cluster_shape': 'uniform', 'NoisePercentage': 0.5, 'UniformNoise': True, 'mean_uncertainty': 20, 'dev_uncertainty': 3, 'N_photons': 150, 'elongation': 1, 'NumberOfScales': 1}\n",
      "in generate different sizes\n",
      "{'x_lim': [0, 4], 'y_lim': [0, 4], 'NumberOfClusters': 40, 'LocPerCluster': [24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24], 'r': [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30], 'cluster_shape': 'uniform', 'NoisePercentage': 0.5, 'UniformNoise': False, 'mean_uncertainty': 20, 'dev_uncertainty': 3, 'N_photons': 150, 'elongation': 1, 'NumberOfScales': 1}\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "creating non uniform noise\n",
      "in generate standard\n",
      "{'x_lim': [0, 4], 'y_lim': [0, 4], 'NumberOfClusters': 40, 'LocPerCluster': [24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24], 'r': [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30], 'cluster_shape': 'uniform', 'NoisePercentage': 0.5, 'UniformNoise': True, 'mean_uncertainty': 20, 'dev_uncertainty': 3, 'N_photons': 150, 'elongation': 1, 'NumberOfScales': 1}\n",
      "in generate high noise\n",
      "{'x_lim': [0, 4], 'y_lim': [0, 4], 'NumberOfClusters': 40, 'LocPerCluster': [24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24], 'r': [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30], 'cluster_shape': 'uniform', 'NoisePercentage': 0.75, 'UniformNoise': True, 'mean_uncertainty': 20, 'dev_uncertainty': 3, 'N_photons': 150, 'elongation': 1, 'NumberOfScales': 1}\n",
      "in generate low density\n",
      "{'x_lim': [0, 4], 'y_lim': [0, 4], 'NumberOfClusters': 40, 'LocPerCluster': [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12], 'r': [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30], 'cluster_shape': 'uniform', 'NoisePercentage': 0.5, 'UniformNoise': True, 'mean_uncertainty': 20, 'dev_uncertainty': 3, 'N_photons': 150, 'elongation': 1, 'NumberOfScales': 1}\n"
     ]
    }
   ],
   "source": [
    "Generate_DifferentDensities(general_path, 30)\n",
    "Generate_DifferentSizes(general_path, 30)\n",
    "Generate_NonUniformNoise(general_path, 30)\n",
    "Generate_Standard(general_path, 30)\n",
    "Generate_HighNoise(general_path, 30)\n",
    "Generate_LowDensity(general_path, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/Eliana/Documents/PDM/Codes/My_codes/Data/figures/'\n",
    "\n",
    "datagen2.save_fig_pdf(path, name, dot_size = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_parameters = {'x_lim': x_lim , 'y_lim': y_lim, 'NumberOfClusters': NumberOfClusters, \n",
    "                  'LocPerCluster': LocPerCluster, 'r': r , 'SNR': SNR, \n",
    "                  'delta': delta, 'NumberOfScales': NumberOfScales,\n",
    "                  'cluster_shape' : cluster_shape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/Eliana/Documents/PDM/Codes/My_codes/Data/'+ name + '_param.txt', 'w') as f:\n",
    "    print(dict_parameters, file=f)\n",
    "    print('# ' + comment, file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen2.save_to_csv('/Users/Eliana/Documents/PDM/Codes/My_codes/Data', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen2.plot_points(dot_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir si on peut dessiner et sauver la figure après coup, après avoir généré et sauver les points en csv: C'est bon ça marche en mettant en numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_points(dat[['x', 'y']].to_numpy(), dat['labels_1'].to_numpy(), 'test', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauver les figures. 5 mai, pour meeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region of interest :\n",
    "x_lim = [0, 4] # micrometer\n",
    "y_lim = [0, 4]\n",
    "\n",
    "# Clusters :\n",
    "NumberOfClusters = 40\n",
    "LocPerCluster    = [25] * NumberOfClusters\n",
    "r                = [30] * NumberOfClusters # nm\n",
    "SNR              = 0.25 \n",
    "delta            = 1 #nm\n",
    "cluster_shape    = 'uniform'\n",
    "\n",
    "NumberOfScales   = 1\n",
    "\n",
    "\n",
    "name = 'simulated_SMLM_4'\n",
    "\n",
    "datagen2 = DataGenerator(x_lim = x_lim,\n",
    "                        y_lim = y_lim,\n",
    "                        NumberOfClusters = NumberOfClusters,\n",
    "                        LocPerCluster = LocPerCluster,\n",
    "                        r = r,\n",
    "                        SNR = SNR,\n",
    "                        NumberOfScales = NumberOfScales,\n",
    "                        delta = delta, cluster_shape = cluster_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/Eliana/Documents/PDM/Codes/My_codes/Data/figures/'\n",
    "\n",
    "datagen2.save_fig_pdf(path, name, dot_size = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Clusters of different densities --------\n",
    "    \n",
    "# Region of interest :\n",
    "x_lim = [0, 4] # micrometer\n",
    "y_lim = [0, 4]\n",
    "\n",
    "# Clusters :\n",
    "NumberOfClusters = 40\n",
    "mean_density     = 25\n",
    "dev              = 15\n",
    "r                = [30] * NumberOfClusters # nm\n",
    "\n",
    "IsolatedLoc      = 500 # absolute number \n",
    "delta            = 1 #nm\n",
    "cluster_shape    = 'uniform'\n",
    "\n",
    "NumberOfScales   = 1\n",
    "\n",
    "# Many simulations:\n",
    "NumberOfSimulations = 30\n",
    "\n",
    "name = 'simulated_SMLM_4'\n",
    "\n",
    "LocPerCluster   = np.random.uniform(low = mean_density - dev, high = mean_density + dev,\n",
    "                                size = (NumberOfClusters, 1))\n",
    "\n",
    "LocPerCluster  = [int(n) for n in LocPerCluster]\n",
    "\n",
    "datagen2 = DataGenerator(x_lim = x_lim,\n",
    "                        y_lim = y_lim,\n",
    "                        NumberOfClusters = NumberOfClusters,\n",
    "                        LocPerCluster = LocPerCluster,\n",
    "                        r = r,\n",
    "                        IsolatedLoc = IsolatedLoc,\n",
    "                        NumberOfScales = NumberOfScales,\n",
    "                        delta = delta, cluster_shape = cluster_shape) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/Eliana/Documents/PDM/Codes/My_codes/Data/figures/'\n",
    "\n",
    "datagen2.save_fig_pdf(path, name, dot_size = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Clusters of different sizes --------\n",
    "    \n",
    "# Region of interest :\n",
    "x_lim = [0, 4] # micrometer\n",
    "y_lim = [0, 4]\n",
    "\n",
    "# Clusters :\n",
    "NumberOfClusters = 40\n",
    "mean_r           = 30\n",
    "dev_r            = 20\n",
    "density          = 25/(math.pi * mean_r**2)\n",
    "\n",
    "r               = np.random.uniform(low = mean_r - dev_r, high = mean_r + dev_r,\n",
    "                                    size = NumberOfClusters)\n",
    "\n",
    "\n",
    "\n",
    "LocPerCluster   = [int(math.pi * rad **2  * density + 0.5) for rad in r]\n",
    "\n",
    "\n",
    "IsolatedLoc      = 500 # absolute number \n",
    "delta            = 1 #nm\n",
    "cluster_shape    = 'uniform'\n",
    "\n",
    "NumberOfScales   = 1\n",
    "\n",
    "\n",
    "\n",
    "name = 'simulated_SMLM_5'\n",
    "\n",
    "\n",
    "datagen2 = DataGenerator(x_lim = x_lim,\n",
    "                        y_lim = y_lim,\n",
    "                        NumberOfClusters = NumberOfClusters,\n",
    "                        LocPerCluster = LocPerCluster,\n",
    "                        r = r,\n",
    "                        IsolatedLoc = IsolatedLoc,\n",
    "                        NumberOfScales = NumberOfScales,\n",
    "                        delta = delta, cluster_shape = cluster_shape) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/Eliana/Documents/PDM/Codes/My_codes/Data/figures/'\n",
    "\n",
    "datagen2.save_fig_pdf(path, name, dot_size = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "r   = np.random.uniform(20, 60, size = 40)\n",
    "\n",
    "density          = 24/(math.pi * 30**2)\n",
    "        \n",
    "LocPerClus = [int(density * math.pi * radius**2) for radius in r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31,\n",
       " 30,\n",
       " 64,\n",
       " 58,\n",
       " 89,\n",
       " 88,\n",
       " 82,\n",
       " 85,\n",
       " 74,\n",
       " 17,\n",
       " 27,\n",
       " 23,\n",
       " 21,\n",
       " 37,\n",
       " 24,\n",
       " 80,\n",
       " 81,\n",
       " 40,\n",
       " 80,\n",
       " 78,\n",
       " 56,\n",
       " 29,\n",
       " 44,\n",
       " 46,\n",
       " 49,\n",
       " 28,\n",
       " 49,\n",
       " 93,\n",
       " 59,\n",
       " 27,\n",
       " 13,\n",
       " 82,\n",
       " 77,\n",
       " 24,\n",
       " 57,\n",
       " 70,\n",
       " 78,\n",
       " 53,\n",
       " 27,\n",
       " 50]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LocPerClus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
