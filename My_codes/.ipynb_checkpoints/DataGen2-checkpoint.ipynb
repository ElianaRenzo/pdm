{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from sklearn import metrics\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./functions_for_GrapHiC.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point():\n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.label = []\n",
    "        \n",
    "        self.x_collected, self.y_collected = x,y # by default, if the point undergoes no perturbation, the coordinates collected are the GT coordiantes \n",
    "        \n",
    "    def add_label(self, label_to_add):\n",
    "        self.label.append(label_to_add)\n",
    "        \n",
    "        \n",
    "    def Scramble(self, delta):\n",
    "        mean = [0,0]\n",
    "        cov_scramble = [[delta**2, 0], [0, delta**2]]\n",
    "        coord_collected     = np.sum([np.array([self.x,self.y]),\n",
    "                                        np.random.multivariate_normal(mean, cov_scramble)],\n",
    "                                        axis = 0)\n",
    "        self.x_collected = coord_collected[0]\n",
    "        self.y_collected = coord_collected[1]\n",
    "        \n",
    "    def GetCoord(self):\n",
    "        return np.array([self.x_collected,self.y_collected])\n",
    "    \n",
    "    def GetCoord_GT(self):\n",
    "        return np.array([self.x,self.y])\n",
    "    \n",
    "    def Isin(self, cluster, delta = 2):\n",
    "        diff = cluster.center -  self.GetCoord_GT()\n",
    "        if np.linalg.norm(cluster.center -  self.GetCoord_GT()) < (cluster.radius + delta): return True\n",
    "        else: return False \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cluster():\n",
    "    def __init__(self, center, radius, label):\n",
    "        self.center = center\n",
    "        self.radius = radius\n",
    "        self.points = []\n",
    "        self.label  = label\n",
    "        \n",
    "        \n",
    "    def Fill(self, NumberOfPoints, cluster_shape):\n",
    "        \n",
    "        if cluster_shape == 'uniform':\n",
    "            temp = uniform_cluster(self.radius, NumberOfPoints, self.center)\n",
    "        if cluster_shape == 'gaussian':\n",
    "            temp = gaussian_cluster((self.radius / 2), NumberOfPoints, self.center)\n",
    "            \n",
    "        for t in temp: \n",
    "            new_point = Point(x = t[0], y = t[1])\n",
    "            new_point.add_label(self.label)\n",
    "            self.points.append(new_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 NumberOfClusters, LocPerCluster, r, SNR,\n",
    "                 NumberOfScales = 1,\n",
    "                 delta = 1,\n",
    "                 x_lim = [-5, 5], y_lim = [-5, 5],\n",
    "                 cluster_shape = 'uniform'):\n",
    "        \n",
    "        # frame shape\n",
    "        self.xmin, self.xmax = 1000 * x_lim[0], 1000 * x_lim[1] # from micrometer to nanometer \n",
    "        self.ymin, self.ymax = 1000 * y_lim[0], 1000 * y_lim[1]\n",
    "        \n",
    "        # parameters \n",
    "        self.NumberOfClusters = NumberOfClusters\n",
    "        self.numbers          = LocPerCluster\n",
    "\n",
    "        self.r                = r\n",
    "        self.IsolatedLoc      = IsolatedLoc\n",
    "        self.cluster_shape    = cluster_shape\n",
    "        self.delta            = delta \n",
    "        self.SNR              = SNR\n",
    "        self.IsolatedLoc      = int(sum(LocPerCluster) / self.SNR)\n",
    "        \n",
    "        # initialise an exmpty clusters list: \n",
    "        self.Clusters = []\n",
    "        \n",
    "        # initialise a empty list of Isolated points:\n",
    "        self.IsolatedPoints = []\n",
    "        \n",
    "\n",
    "        \n",
    "        #for s in range(NumberOfScales):\n",
    "        #    print('s = ', s )\n",
    "        \n",
    "        # data generation steps\n",
    "        self.CreateClusters()\n",
    "        self.AddIsolatedLoc()\n",
    "        #self.AddIsolatedLoc_NonUniform()\n",
    "        #self.AddIsolatedLoc_NonUniformGaussian()\n",
    "        #self.AddIsolatedLoc_NonUniformFinal()\n",
    "        \n",
    "    def PlaceCenters(self):\n",
    "        # ------ Version with |ci - cj| < 2*rmax: ------\n",
    "        # Place a first cluster \n",
    "        self.centers      = np.random.uniform(low=[self.xmin + self.r[0], self.ymin + self.r[0]],\n",
    "                                              high=[self.xmax - self.r[0], self.ymax - self.r[0]],\n",
    "                                              size=(1,2))\n",
    "        \n",
    "        n = 1      # n is the n^th cluster \n",
    "        count = 0  # for avoiding endless loop\n",
    "        while (n < self.NumberOfClusters) and (count < (self.NumberOfClusters * 10)): # 10 is arbitrarily chosen\n",
    "            count += 1\n",
    "            if (count  == ((self.NumberOfClusters * 10) -2) ): print('cannot place any more clusters')\n",
    "            new_center = np.random.uniform(low=[self.xmin + self.r[n], self.ymin + self.r[n]],\n",
    "                                              high=[self.xmax-self.r[n], self.ymax-self.r[n]],\n",
    "                                              size=(1,2))\n",
    "            is_accepted = True\n",
    "            for i, c in enumerate(self.centers):\n",
    "                if np.linalg.norm(c - new_center) < (self.r[i] + self.r[n]): is_accepted = False # checking that there will be no overlap\n",
    "            \n",
    "            if is_accepted: \n",
    "                n += 1\n",
    "                self.centers = np.vstack([self.centers, new_center])\n",
    "            \n",
    "            \n",
    "    def InitializeClusters(self):\n",
    "        # Creates the Cluster objects\n",
    "        for i, center in enumerate(self.centers):   \n",
    "            self.Clusters.append(Cluster(center, self.r[i], label = i+1))    # first cluster has label = 1. Label = 0 indicates noise. \n",
    "\n",
    "    def FillClusters(self):\n",
    "        # This method calls the Fill method for each cluster. Fill will create n points in the cluster. \n",
    "        for i, cluster in enumerate(self.Clusters):\n",
    "            if (self.cluster_shape != 'uniform') and (self.cluster_shape != 'gaussian'): print('cluster_shape must be \"uniform\" or \"gaussian\"')\n",
    "            else: cluster.Fill(self.numbers[i], self.cluster_shape)\n",
    "        \n",
    "    def Scramble(self):\n",
    "        for cluster in self.Clusters:\n",
    "            for point in cluster.points: \n",
    "                point.Scramble(self.delta)\n",
    "    \n",
    "    def CreateClusters(self):\n",
    "        self.PlaceCenters()\n",
    "        self.InitializeClusters()\n",
    "        self.FillClusters()\n",
    "        self.Scramble()\n",
    "        \n",
    "    \n",
    "    def AddIsolatedLoc(self):\n",
    "        # This method creates Isolated points, randomly distributed, but avoiding the cluster areas. \n",
    "        n = 0  # n counts the number of isolated locations that are added to the data\n",
    "        \n",
    "        while n < self.IsolatedLoc:\n",
    "            new_noise = np.random.uniform(low=[self.xmin, self.ymin], high=[self.xmax, self.ymax], size=(1,2))\n",
    "            new_noise = Point(new_noise[0][0], new_noise[0][1]) # putting it in a Point variable, to use its methods.\n",
    "            new_noise.add_label(0)  # 0 label is for noise\n",
    "            \n",
    "            # If the new point is in a cluster, discard it. \n",
    "            is_accepted = True \n",
    "            for cluster in self.Clusters: \n",
    "                if new_noise.Isin(cluster, delta = self.delta): is_accepted = False\n",
    "                \n",
    "            if is_accepted: \n",
    "                self.IsolatedPoints.append(new_noise)\n",
    "                n += 1\n",
    "            \n",
    "    def AddIsolatedLoc_NonUniformFinal(self):\n",
    "    \n",
    "        #s = np.random.normal(mu, sigma, 1000)\n",
    "        \n",
    "        n = 0  # n counts the number of isolated locations that are added to the data\n",
    "        sigma_x = (self.xmax - self.xmin)/2.5\n",
    "        \n",
    "        while n < self.IsolatedLoc:\n",
    "            new_y = np.random.uniform(low=self.ymin, high= self.ymax)\n",
    "            new_x = abs(np.random.normal(self.xmin, sigma_x)) # take the absolute value of a gaussian, to have a continuously decreasing distribution\n",
    "            new_noise = Point(new_x, new_y) # putting it in a Point variable, to use its methods.\n",
    "            new_noise.add_label(0)  # 0 label is for noise\n",
    "            \n",
    "            # If the new point is in a cluster, discard it. \n",
    "            is_accepted = True \n",
    "            if ((new_noise.x < self.xmin) or (new_noise.x > self.xmax)): is_accepted = False\n",
    "            for cluster in self.Clusters: \n",
    "                if new_noise.Isin(cluster, delta = self.delta): is_accepted = False\n",
    "                \n",
    "            if is_accepted: \n",
    "                self.IsolatedPoints.append(new_noise)\n",
    "                n += 1\n",
    "        \n",
    "\n",
    "    def AddIsolatedLoc_NonUniform(self):\n",
    "        \n",
    "        n = 0  # n counts the number of isolated locations that are added to the data\n",
    "        \n",
    "        HalfIsol    = int(self.IsolatedLoc)\n",
    "        \n",
    "        # Fill a first \"layer\" everywhere: \n",
    "        while n < HalfIsol:\n",
    "            new_noise = np.random.uniform(low=[self.xmin, self.ymin], high=[self.xmax, self.ymax], size=(1,2))\n",
    "            new_noise = Point(new_noise[0][0], new_noise[0][1]) # putting it in a Point variable, to use its methods.\n",
    "            new_noise.add_label(0)  # 0 label is for noise\n",
    "            \n",
    "            # If the new point is in a cluster, discard it. \n",
    "            is_accepted = True \n",
    "            for cluster in self.Clusters: \n",
    "                if new_noise.Isin(cluster, delta = self.delta): is_accepted = False\n",
    "                \n",
    "            if is_accepted: \n",
    "                self.IsolatedPoints.append(new_noise)\n",
    "                n += 1\n",
    "                \n",
    "        n = 0\n",
    "        # Fill a second \"layer\" only on the\n",
    "        while n < HalfIsol:\n",
    "            new_noise = np.random.uniform(low=[self.xmin, self.ymin], high=[self.xmax/2, self.ymax], size=(1,2))\n",
    "            new_noise = Point(new_noise[0][0], new_noise[0][1]) # putting it in a Point variable, to use its methods.\n",
    "            new_noise.add_label(0)  # 0 label is for noise\n",
    "            \n",
    "            # If the new point is in a cluster, discard it. \n",
    "            is_accepted = True \n",
    "            for cluster in self.Clusters: \n",
    "                if new_noise.Isin(cluster, delta = self.delta): is_accepted = False\n",
    "                \n",
    "            if is_accepted: \n",
    "                self.IsolatedPoints.append(new_noise)\n",
    "                n += 1\n",
    "            \n",
    "        \n",
    "    def GetPointsCoord(self):\n",
    "        # returns in an  numpy array the info about all cluster points + noise points\n",
    "        points  = np.array([[0, 0]]) \n",
    "        \n",
    "        # Points from the Clusters\n",
    "        for cluster in self.Clusters:\n",
    "            for p in cluster.points: \n",
    "                points = np.vstack([points, p.GetCoord()]) # extend the array with next points\n",
    "                \n",
    "        # Isolated Points\n",
    "        for isolated in self.IsolatedPoints: \n",
    "            points = np.vstack([points, isolated.GetCoord()])\n",
    "        \n",
    "        return points[1:]\n",
    "            \n",
    "    def GetPointsLabels(self):\n",
    "        labels = []\n",
    "        for cluster in self.Clusters: \n",
    "            for p in cluster.points: \n",
    "                labels.append(p.label[0])\n",
    "                \n",
    "        for isolated in self.IsolatedPoints:\n",
    "            labels.append(isolated.label[0])\n",
    "        return labels\n",
    "    \n",
    "    def plot_points(self, dot_size = 1):\n",
    "        P1              = self.GetPointsCoord()\n",
    "        labels          = self.GetPointsLabels()\n",
    "        plot_points(P1, labels, 'Input Data: GT', dot_size)\n",
    "        plot_points(P1, len(labels) * [0], 'Input Data', dot_size)\n",
    "    \n",
    "    def save_fig_pdf(self, path, filename = 'generated_SMLM_untitled', dot_size = 0.01):\n",
    "        P1              = self.GetPointsCoord()\n",
    "        labels          = self.GetPointsLabels()\n",
    "        save_fig_pdf(P1, labels, path, filename, dot_size)\n",
    "        \n",
    "    def GetAllData(self):\n",
    "        # concatenate the positions and the label associated, in a pandas dataframe variable,\n",
    "        # with columns names: x, y, labels_1, ..., labels_s, s the number of scales \n",
    "        df_xy    = pd.DataFrame(self.GetPointsCoord(), columns = ['x','y'])\n",
    "        df_l     = pd.DataFrame(self.GetPointsLabels(), columns= ['labels_1'])\n",
    "        df_final = pd.concat([df_xy, df_l], axis = 1)\n",
    "        return df_final\n",
    "        \n",
    "    def save_to_csv(self, path, filename):\n",
    "        # This function saves a .csv file with columns: x, y, and labels. Each row corresponds to one point.\n",
    "        # Give the filename without .csv, and the path without / \n",
    "        # Il faudra ajouter une autre colonne pour toutes les autres échelles\n",
    "\n",
    "        df_final = self.GetAllData()\n",
    "        df_final.to_csv(path + '/' + filename + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datagen.save_to_csv('/Users/Eliana/Documents/PDM', 'essai_datagen2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test = pd.read_csv('/Users/Eliana/Documents/PDM/essai_datagen2.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for cluster in datagen.Clusters: \n",
    "    print(cluster.center)\n",
    "print(len(datagen.centers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for cluster in datagen.Clusters: \n",
    "    for p in cluster.points:\n",
    "        print(p.x, p.y)\n",
    "        print('label:', p.label[0])\n",
    "        print(p.x_collected, p.y_collected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[x,y] = np.array([np.sum([p, np.random.multivariate_normal(mean, cov_scramble)],\n",
    "                                        axis = 0) for p in self.cluster_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
