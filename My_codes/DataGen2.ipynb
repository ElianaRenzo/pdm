{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from sklearn import metrics\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./functions_for_GrapHiC.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point():\n",
    "    def __init__(self,x,y, cov_matrix = [[400, 0], [0, 400]], N = 150, sigma = 20):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.label = []\n",
    "        self.cov_matrix = cov_matrix #[[delta**2, 0], [0, delta**2]]\n",
    "        self.N = N\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        self.x_collected, self.y_collected = x,y # by default, if the point undergoes no perturbation, the coordinates collected are the GT coordiantes \n",
    "        \n",
    "    def add_label(self, label_to_add):\n",
    "        self.label.append(label_to_add)\n",
    "        \n",
    "    def Scramble(self):\n",
    "        mean = [0,0]\n",
    "        #cov_scramble = [[delta**2, 0], [0, delta**2]]\n",
    "        coord_collected     = np.sum([np.array([self.x,self.y]),\n",
    "                                        np.random.multivariate_normal(mean, self.cov_matrix)],\n",
    "                                        axis = 0)\n",
    "        self.x_collected = coord_collected[0]\n",
    "        self.y_collected = coord_collected[1]\n",
    "        \n",
    "    def GetCoord(self):\n",
    "        return np.array([self.x_collected,self.y_collected])\n",
    "    \n",
    "    def GetCoord_GT(self):\n",
    "        return np.array([self.x,self.y])\n",
    "    \n",
    "    def Isin(self, cluster, delta = 10):\n",
    "        diff = cluster.center -  self.GetCoord_GT()\n",
    "        if np.linalg.norm(cluster.center -  self.GetCoord_GT()) < (cluster.radius + delta): return True\n",
    "        else: return False \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cluster():\n",
    "    def __init__(self, center, radius, label):\n",
    "        self.center = center\n",
    "        self.radius = radius\n",
    "        self.points = []\n",
    "        self.label  = label\n",
    "        \n",
    "        \n",
    "    def Fill(self, NumberOfPoints, cluster_shape, mean_uncertainty, dev_uncertainty, N_photons):\n",
    "        \n",
    "        if cluster_shape == 'uniform':\n",
    "            temp = uniform_cluster(self.radius, NumberOfPoints, self.center)\n",
    "        if cluster_shape == 'gaussian':\n",
    "            temp = gaussian_cluster((self.radius / 2), NumberOfPoints, self.center)\n",
    "            \n",
    "        for t in temp:\n",
    "            uncert = np.random.normal(mean_uncertainty, dev_uncertainty)\n",
    "            cov_matrix = [[uncert**2, 0], [0, uncert**2]]\n",
    "            new_point = Point(x = t[0], y = t[1], cov_matrix = cov_matrix, N = N_photons, sigma = uncert)\n",
    "            new_point.add_label(self.label)\n",
    "            self.points.append(new_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElongCluster(Cluster):\n",
    "    # This is a Cluster subclass \n",
    "    def __init__(self, center, radius, elongation, label):\n",
    "        super().__init__(center, radius, label)\n",
    "        self.elongation = elongation\n",
    "        self.a = self.radius\n",
    "        self.b = self.elongation * self.radius\n",
    "        \n",
    "        self.orientation = np.random.uniform(low = 0, high = math.pi)\n",
    "        cos, sin = math.cos(self.orientation), math.sin(self.orientation)\n",
    "        self.R_matrix = np.array([[cos, -sin], [sin, cos]])\n",
    "        \n",
    "        \n",
    "    def Isin(self, point, delta):\n",
    "        return False\n",
    "        '''\n",
    "        point_\n",
    "        print('in Cluster.Isin()')\n",
    "        print('self.center = ', self.center)\n",
    "        print('point.Coord = ', point.GetCoord_GT())\n",
    "        print('self.radius = ', self.radius)\n",
    "        diff = self.center - point.GetCoord_GT()\n",
    "        if np.linalg.norm(self.center - point.GetCoord_GT()) < (self.radius + delta): return True\n",
    "        else: return False \n",
    "        '''\n",
    "        \n",
    "        \n",
    "    def Fill(self, NumberOfPoints, cluster_shape, mean_uncertainty, dev_uncertainty, N_photons,):\n",
    "        \n",
    "        temp = elliptical_cluster(self.a, self.b, self.R_matrix, NumberOfPoints, self.center)\n",
    "        oriented = temp\n",
    "        #oriented = [np.dot(self.R_matrix, p) for p in temp]\n",
    "\n",
    "        for p in oriented:\n",
    "            uncert = np.random.normal(mean_uncertainty, dev_uncertainty)\n",
    "            cov_matrix = [[uncert**2, 0], [0, uncert**2]]\n",
    "            new_point = Point(x = p[0], y = p[1], cov_matrix = cov_matrix, N = N_photons, sigma = uncert)\n",
    "            new_point.add_label(self.label)\n",
    "            self.points.append(new_point)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 NumberOfClusters, LocPerCluster, r, NoisePercentage = 0.5,\n",
    "                 NumberOfScales = 1,\n",
    "                 x_lim = [-5, 5], y_lim = [-5, 5],\n",
    "                 cluster_shape = 'uniform',\n",
    "                 UniformNoise = True,\n",
    "                 mean_delta = 20, dev_delta = 3, N_photons = 150,\n",
    "                 elongation = 1):\n",
    "        \n",
    "        # frame shape\n",
    "        self.xmin, self.xmax = 1000 * x_lim[0], 1000 * x_lim[1] # from micrometer to nanometer \n",
    "        self.ymin, self.ymax = 1000 * y_lim[0], 1000 * y_lim[1]\n",
    "        \n",
    "        # parameters \n",
    "        self.NumberOfClusters = NumberOfClusters\n",
    "        self.numbers          = LocPerCluster\n",
    "\n",
    "        self.r                = r\n",
    "        #self.IsolatedLoc      = IsolatedLoc\n",
    "        self.cluster_shape    = cluster_shape\n",
    "        #self.delta            = delta \n",
    "        self.NoisePercentage  = NoisePercentage\n",
    "        self.IsolatedLoc      = int((sum(LocPerCluster) * NoisePercentage) / (1-NoisePercentage))\n",
    "        \n",
    "        self.mean_delta       = mean_delta\n",
    "        self.dev_delta        = dev_delta\n",
    "        self.N_photons        = N_photons\n",
    "        \n",
    "        # initialise an exmpty clusters list: \n",
    "        self.Clusters = []\n",
    "        \n",
    "        # initialise a empty list of Isolated points:\n",
    "        self.IsolatedPoints = []\n",
    "        \n",
    "        # elongation \n",
    "        self.elongation = elongation \n",
    "        \n",
    "\n",
    "        \n",
    "        #for s in range(NumberOfScales):\n",
    "        #    print('s = ', s )\n",
    "        \n",
    "        # data generation steps\n",
    "        self.CreateClusters()\n",
    "        if (UniformNoise == True):\n",
    "            self.AddIsolatedLoc()\n",
    "        else:\n",
    "            self.AddIsolatedLoc_NonUniformFinal()\n",
    "        \n",
    "    def PlaceCenters(self):\n",
    "        # ------ Version with |ci - cj| < 2*rmax: ------\n",
    "        # Place a first cluster \n",
    "        self.centers      = np.random.uniform(low=[self.xmin + self.r[0], self.ymin + self.r[0]],\n",
    "                                              high=[self.xmax - self.r[0], self.ymax - self.r[0]],\n",
    "                                              size=(1,2))\n",
    "        \n",
    "        n = 1      # n is the n^th cluster \n",
    "        count = 0  # for avoiding endless loop\n",
    "        while (n < self.NumberOfClusters) and (count < (self.NumberOfClusters * 10)): # 10 is arbitrarily chosen\n",
    "            count += 1\n",
    "            if (count  == ((self.NumberOfClusters * 10) -2) ): print('cannot place any more clusters')\n",
    "            new_center = np.random.uniform(low=[self.xmin + self.r[n], self.ymin + self.r[n]],\n",
    "                                              high=[self.xmax-self.r[n], self.ymax-self.r[n]],\n",
    "                                              size=(1,2))\n",
    "            is_accepted = True\n",
    "            for i, c in enumerate(self.centers):\n",
    "                if np.linalg.norm(c - new_center) < (self.r[i] + self.r[n] + self.mean_delta): is_accepted = False # checking that there will be no overlap\n",
    "            \n",
    "            if is_accepted: \n",
    "                n += 1\n",
    "                self.centers = np.vstack([self.centers, new_center])\n",
    "            \n",
    "            \n",
    "    def InitializeClusters(self):\n",
    "        # Creates the Cluster objects\n",
    "        if (self.elongation == 1):\n",
    "            for i, center in enumerate(self.centers):   \n",
    "                self.Clusters.append(Cluster(center, self.r[i], label = i+1))    # first cluster has label = 1. Label = 0 indicates noise. \n",
    "        else: \n",
    "            for i, center in enumerate(self.centers):   \n",
    "                self.Clusters.append(ElongCluster(center, self.r[i], self.elongation, label = i+1)) \n",
    "            \n",
    "            \n",
    "    def FillClusters(self):\n",
    "        # This method calls the Fill method for each cluster. Fill will create n points in the cluster. \n",
    "        for i, cluster in enumerate(self.Clusters):\n",
    "            if (self.cluster_shape != 'uniform') and (self.cluster_shape != 'gaussian'): print('cluster_shape must be \"uniform\" or \"gaussian\"')\n",
    "            else: cluster.Fill(self.numbers[i], self.cluster_shape, self.mean_delta, self.dev_delta, self.N_photons)\n",
    "        \n",
    "    def Scramble(self):\n",
    "        for cluster in self.Clusters:\n",
    "            for point in cluster.points: \n",
    "                point.Scramble()\n",
    "    \n",
    "    def CreateClusters(self):\n",
    "        self.PlaceCenters()\n",
    "        self.InitializeClusters()\n",
    "        self.FillClusters()\n",
    "        self.Scramble()\n",
    "        \n",
    "    \n",
    "    def AddIsolatedLoc(self):\n",
    "        # This method creates Isolated points, randomly distributed, but avoiding the cluster areas. \n",
    "        n = 0  # n counts the number of isolated locations that are added to the data\n",
    "        \n",
    "        while n < self.IsolatedLoc:\n",
    "            new_noise = np.random.uniform(low=[self.xmin, self.ymin], high=[self.xmax, self.ymax], size=(1,2))\n",
    "            uncert = np.random.normal(self.mean_delta, self.dev_delta)\n",
    "            cov_matrix = [[uncert**2, 0], [0, uncert**2]]\n",
    "            new_noise = Point(new_noise[0][0], new_noise[0][1], cov_matrix, self.N_photons, uncert) # putting it in a Point variable, to use its methods.\n",
    "            new_noise.add_label(0)  # 0 label is for noise\n",
    "            \n",
    "            # If the new point is in a cluster, discard it. \n",
    "            is_accepted = True \n",
    "            for cluster in self.Clusters: \n",
    "                if new_noise.Isin(cluster, delta = self.mean_delta): is_accepted = False\n",
    "                \n",
    "            if is_accepted: \n",
    "                self.IsolatedPoints.append(new_noise)\n",
    "                n += 1\n",
    "            \n",
    "    def AddIsolatedLoc_NonUniformFinal(self):\n",
    "        print('creating non uniform noise')\n",
    "    \n",
    "        #s = np.random.normal(mu, sigma, 1000)\n",
    "        \n",
    "        n = 0  # n counts the number of isolated locations that are added to the data\n",
    "        sigma_x = (self.xmax - self.xmin)/2.0\n",
    "        \n",
    "        while n < self.IsolatedLoc:\n",
    "            new_y = np.random.uniform(low=self.ymin, high= self.ymax)\n",
    "            new_x = abs(np.random.normal(self.xmin, sigma_x)) # take the absolute value of a gaussian, to have a continuously decreasing distribution\n",
    "            uncert = np.random.normal(self.mean_delta, self.dev_delta)\n",
    "            cov_matrix = [[uncert**2, 0], [0, uncert**2]]\n",
    "            new_noise = Point(new_x, new_y, cov_matrix, self.N_photons, uncert)\n",
    "            new_noise.add_label(0)  # 0 label is for noise\n",
    "            \n",
    "            # If the new point is in a cluster, discard it. \n",
    "            is_accepted = True \n",
    "            if ((new_noise.x < self.xmin) or (new_noise.x > self.xmax)): is_accepted = False\n",
    "            for cluster in self.Clusters: \n",
    "                if new_noise.Isin(cluster, delta = self.mean_delta): is_accepted = False\n",
    "                \n",
    "            if is_accepted: \n",
    "                self.IsolatedPoints.append(new_noise)\n",
    "                n += 1\n",
    "        \n",
    "\n",
    "    def AddIsolatedLoc_NonUniform_test(self):\n",
    "        #supprimer cette méthode\n",
    "        \n",
    "        n = 0  # n counts the number of isolated locations that are added to the data\n",
    "        \n",
    "        HalfIsol    = int(self.IsolatedLoc)\n",
    "        \n",
    "        # Fill a first \"layer\" everywhere: \n",
    "        while n < HalfIsol:\n",
    "            new_noise = np.random.uniform(low=[self.xmin, self.ymin], high=[self.xmax, self.ymax], size=(1,2))\n",
    "            new_noise = Point(new_noise[0][0], new_noise[0][1]) # putting it in a Point variable, to use its methods.\n",
    "            new_noise.add_label(0)  # 0 label is for noise\n",
    "            \n",
    "            # If the new point is in a cluster, discard it. \n",
    "            is_accepted = True \n",
    "            for cluster in self.Clusters: \n",
    "                if new_noise.Isin(cluster, delta = self.mean_delta): is_accepted = False\n",
    "                \n",
    "            if is_accepted: \n",
    "                self.IsolatedPoints.append(new_noise)\n",
    "                n += 1\n",
    "                \n",
    "        n = 0\n",
    "        # Fill a second \"layer\" only on the\n",
    "        while n < HalfIsol:\n",
    "            new_noise = np.random.uniform(low=[self.xmin, self.ymin], high=[self.xmax/2, self.ymax], size=(1,2))\n",
    "            new_noise = Point(new_noise[0][0], new_noise[0][1] ) # putting it in a Point variable, to use its methods.\n",
    "            new_noise.add_label(0)  # 0 label is for noise\n",
    "            \n",
    "            # If the new point is in a cluster, discard it. \n",
    "            is_accepted = True \n",
    "            for cluster in self.Clusters: \n",
    "                if new_noise.Isin(cluster, delta = self.mean_delta): is_accepted = False\n",
    "                \n",
    "            if is_accepted: \n",
    "                self.IsolatedPoints.append(new_noise)\n",
    "                n += 1\n",
    "            \n",
    "        \n",
    "    \n",
    "    def GetPointsCoord(self):\n",
    "        # returns in an  numpy array the info about all cluster points + noise points\n",
    "        points  = np.array([[0, 0]]) \n",
    "        \n",
    "        # Points from the Clusters\n",
    "        for cluster in self.Clusters:\n",
    "            for p in cluster.points: \n",
    "                points = np.vstack([points, p.GetCoord()]) # extend the array with next points\n",
    "                \n",
    "        # Isolated Points\n",
    "        for isolated in self.IsolatedPoints: \n",
    "            points = np.vstack([points, isolated.GetCoord()])\n",
    "        \n",
    "        return points[1:]\n",
    "            \n",
    "    def GetPointsLabels(self):\n",
    "        labels = []\n",
    "        for cluster in self.Clusters: \n",
    "            for p in cluster.points: \n",
    "                labels.append(p.label[0])\n",
    "                \n",
    "        for isolated in self.IsolatedPoints:\n",
    "            labels.append(isolated.label[0])\n",
    "        return labels\n",
    "    \n",
    "    def GetPointsCovMatrix(self):\n",
    "        Covs = []\n",
    "        for cluster in self.Clusters: \n",
    "            for p in cluster.points: \n",
    "                Covs.append(p.cov_matrix)\n",
    "                \n",
    "        for isolated in self.IsolatedPoints:\n",
    "            Covs.append(isolated.cov_matrix)\n",
    "            \n",
    "        return Covs\n",
    "        \n",
    "    def GetPointsDistribution(self):\n",
    "        sigma_and_N  = np.array([[0, 0]]) \n",
    "\n",
    "        for cluster in self.Clusters:\n",
    "            for p in cluster.points: \n",
    "                sigma_and_N = np.vstack([sigma_and_N, np.array([p.sigma, p.N])]) # extend the array with next points\n",
    "                \n",
    "        for isolated in self.IsolatedPoints:\n",
    "            sigma_and_N = np.vstack([sigma_and_N, np.array([isolated.sigma, isolated.N])])\n",
    "          \n",
    "        return sigma_and_N[1:]       \n",
    "    \n",
    "    def plot_points(self, dot_size = 1):\n",
    "        P1              = self.GetPointsCoord()\n",
    "        labels          = self.GetPointsLabels()\n",
    "        plot_points(P1, labels, 'Input Data: GT', dot_size)\n",
    "        plot_points(P1, len(labels) * [0], 'Input Data', dot_size)\n",
    "    \n",
    "    def save_fig_pdf(self, path, filename = 'generated_SMLM_untitled', dot_size = 0.01):\n",
    "        P1              = self.GetPointsCoord()\n",
    "        labels          = self.GetPointsLabels()\n",
    "        save_fig_pdf(P1, labels, path, filename, dot_size)\n",
    "        \n",
    "    def GetAllData(self):\n",
    "        # concatenate the positions and the label associated, in a pandas dataframe variable,\n",
    "        # with columns names: x, y, labels_1, ..., labels_s, s the number of scales \n",
    "        df_xy    = pd.DataFrame(self.GetPointsCoord(), columns = ['x','y'])\n",
    "        df_l     = pd.DataFrame(self.GetPointsLabels(), columns= ['labels_1'])\n",
    "        df_d     = pd.DataFrame(self.GetPointsDistribution(), columns = ['sigma', 'N_photons'])\n",
    "        df_cov   = pd.DataFrame({'cov_matrix': self.GetPointsCovMatrix()})\n",
    "        df_final = pd.concat([df_xy, df_l, df_d, df_cov], axis = 1)\n",
    "        return df_final\n",
    "        \n",
    "    def save_to_csv(self, path, filename):\n",
    "        # This function saves a .csv file with columns: x, y, and labels. Each row corresponds to one point.\n",
    "        # Give the filename without .csv, and the path without / \n",
    "        # Il faudra ajouter une autre colonne pour toutes les autres échelles\n",
    "\n",
    "        df_final = self.GetAllData()\n",
    "        df_final.to_csv(path + '/' + filename + '.csv', index = False)\n",
    "        \n",
    "    def GetPoints(self):\n",
    "        # This method returns a list of all the points (type Point) in the ROI\n",
    "        Points = []\n",
    "        for cluster in self.Clusters:\n",
    "            for p in cluster.points:\n",
    "                Points.append(p)  \n",
    "        for isolated in self.IsolatedPoints:\n",
    "            Points.append(isolated)\n",
    "        return Points\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datagen.save_to_csv('/Users/Eliana/Documents/PDM', 'essai_datagen2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test = pd.read_csv('/Users/Eliana/Documents/PDM/essai_datagen2.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for cluster in datagen.Clusters: \n",
    "    print(cluster.center)\n",
    "print(len(datagen.centers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for cluster in datagen.Clusters: \n",
    "    for p in cluster.points:\n",
    "        print(p.x, p.y)\n",
    "        print('label:', p.label[0])\n",
    "        print(p.x_collected, p.y_collected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[x,y] = np.array([np.sum([p, np.random.multivariate_normal(mean, cov_scramble)],\n",
    "                                        axis = 0) for p in self.cluster_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.859189838012774\n"
     ]
    }
   ],
   "source": [
    "class CsrGenerator():\n",
    "    def __init__(self, N, x_lim = [0,4], y_lim = [0,4]):\n",
    "        self.N = N\n",
    "        self.xmin, self.xmax = 1000 * x_lim[0], 1000 * x_lim[1] # from micrometer to nanometer \n",
    "        self.ymin, self.ymax = 1000 * y_lim[0], 1000 * y_lim[1]\n",
    "        \n",
    "        self.Points = []\n",
    "        \n",
    "        self.AddPoints()\n",
    "        \n",
    "\n",
    "    def AddPoints(self):\n",
    "        # this method adds N points, complet\n",
    "        coords = np.random.uniform(low = [self.xmin, self.ymin], high = [self.xmax, self.ymax], size= (self.N, 2))\n",
    "        \n",
    "        cov_matrix = [[0, 0], [0, 0]]\n",
    "        n_photons = 1\n",
    "        \n",
    "        for c in coords:\n",
    "            new_point = Point(c[0], c[1], cov_matrix, n_photons, 0)\n",
    "            new_point.add_label(0)  # 0 label is for noise\n",
    "            self.Points.append(new_point)\n",
    "            \n",
    "    def GetPointsCoord(self):\n",
    "        points  = np.array([[0, 0]]) \n",
    "        for p in self.Points: \n",
    "            points = np.vstack([points, p.GetCoord()]) # extend the array with next points\n",
    "        return points[1:]\n",
    "    \n",
    "    def GetPointsLabels(self):\n",
    "        labels = []\n",
    "        for p in self.Points: \n",
    "            labels.append(p.label[0])\n",
    "        return labels\n",
    "    \n",
    "        \n",
    "    def GetPointsCovMatrix(self):\n",
    "        Covs = [] \n",
    "        for p in self.Points: \n",
    "            Covs.append(p.cov_matrix)\n",
    "        return Covs\n",
    "    \n",
    "    def GetPointsDistribution(self):\n",
    "        sigma_and_N  = np.array([[0, 0]]) \n",
    "        for p in self.Points:\n",
    "            sigma_and_N = np.vstack([sigma_and_N, np.array([p.sigma, p.N])]) # extend the array with next points\n",
    "        return sigma_and_N[1:]         \n",
    "            \n",
    "    def GetAllData(self):\n",
    "        # concatenate the positions and the label associated, in a pandas dataframe variable,\n",
    "        # with columns names: x, y, labels_1, ..., labels_s, s the number of scales \n",
    "        df_xy    = pd.DataFrame(self.GetPointsCoord(), columns = ['x','y'])\n",
    "        df_l     = pd.DataFrame(self.GetPointsLabels(), columns= ['labels_1'])\n",
    "        df_d     = pd.DataFrame(self.GetPointsDistribution(), columns = ['sigma', 'N_photons'])\n",
    "        df_cov   = pd.DataFrame({'cov_matrix': self.GetPointsCovMatrix()})\n",
    "        df_final = pd.concat([df_xy, df_l, df_d, df_cov], axis = 1)\n",
    "        return df_final\n",
    "        \n",
    "    def plot_points(self, dot_size = 1):\n",
    "        P1              = self.GetPointsCoord()\n",
    "        labels          = self.GetPointsLabels()\n",
    "        plot_points(P1, labels, 'CSR', dot_size)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
